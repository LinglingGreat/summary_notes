聚类 Clustering

# 什么是聚类

监督学习：发现数据属性和类别属性之间的关联模式。并通过利用这些模式用来预测未知数据实例的类别属性。

无监督学习：数据没有目标属性。发现数据中存在的内在结构。

聚类（Clustering）是一种发现数据中的相似群（聚类，clusters）的技术。

聚类是一个将数据集中在某些方面相似的数据成员进行分类组织的过程。

一个聚类就是一些数据实例的集合，这个集合中的元素彼此相似；与其他聚类中的元素不同。

**聚类的应用**

聚类既可以作为一个单独过程，用于找寻数据内在的分布结构。也可以作为分类等其他学习任务的前驱过程。

实例1：在营销学中，对客户进行分割，为每组客户指定一个套营销策略，也是采用聚类来完成。

实例2：在生物学上，聚类能用于推导植物和动物的分类，对基因进行分类，获得对种群中固有结构的认识。

事实上，聚类是数据挖掘技术中应用最广泛的技术之一。
发展历史长，应用领域广泛。比如：医学类、心理学、植物学、社会学、生物学、营销学。近年来，在线文档的快速发展，文本聚类研究成为关注的重点。对给定文本，需要根据它们内容的相似性来进行组织。建立一个主题层次。

**聚类的形式定义**

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/cluster1.png)

**影响聚类算法效果的主要原因有：（　）？**

```
特征选取
模式相似性测度
分类准则
已知类别的样本质量
```

正确答案为A B  C。这道题的答案可以从网上找到。http://www.docin.com/p-756247716.html

D之所以不正确，是因为聚类是对无类别的数据进行聚类，不使用已经标记好的数据。

# 聚类算法概述

**聚类算法**

- 原型聚类
- 层次聚类
- 密度聚类

**距离函数**（相似性或相异性）：度量两个数据点（对象）的相似程度。
**聚类评价**

- 类内差异（聚类内部距离）：最小化
- 类间差异（聚类外部距离）：最大化

聚类结果的质量与**算法、距离函数和应用领域**有很大关系。

## K-均值算法

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/cluster2.png)

选择正确的K值 https://byteacademy.co/blog/k-means-clustering/

弯管法  **Elbow Method** 

弯管法允许我们通过视觉辅助对 K 值做出判定。我们试着将我们的数据分解成不同数量的 K 簇，并根据相应的 W（Ck）画出每个 K 簇类型。

$W(C_k)=\frac1{|C_k|}\sum_{i,i'\in C_k}\sum_{j=1}^p{(x_{ij}-x_{i'j})}^2$

![K-means](https://byteacademy.co/wp-content/uploads/2018/07/Screen-Shot-2018-07-14-at-9.12.17-am.png) 

选择W(Ck)值下降最快的地方对应的K值，这里选择K=2

**Silhouette Method/Analysis** 

Silhouette Analysis可以用来学习结果簇之间的间隔距离。Silhouette coefficient度量了一个簇中的每个点和其邻居簇中的点有多接近，因此可以用来评估例如簇的个数这样的参数。取值范围[-1,1].如果这个相关系数接近1说明样本和邻居簇距离很远，0说明样本在两个相邻簇的决策边界上/很接近决策边界，负值说明样本可能分配到了错误的簇。

一个样本的Silhouette coefficient=(b-a)/max(a,b)，b是样本和最近的簇(不是样本所属簇)之间的距离，a是平均簇内距离/方差。

http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html

==**k-means中的邻近度函数**==

1、曼哈顿距离： 质心：中位数。目标函数：最小化对象到其簇质心的距离和

2、平方欧几里德距离。质心：均值。目标函数：最小化对象到其簇质心的距离的平方和

3、余弦。质心：均值。最大化对象与其质心的余弦相似度和

4、Bregman 散度。质心：均值。目标函数：最小化对象到其簇质心的Bregman散度和

## 基于高斯混合分布的聚类

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/cluster3.png)

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/cluster4.png)

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/cluster5.png)

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/cluster6.png)

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/cluster7.png)

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/cluster8.png)

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/cluster9.png)

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/cluster10.png)

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/cluster11.png)

2-12：基于EM算法对参数进行迭代更新

停止条件的设定可以是：1. 达到最大迭代论述，或似然函数LL(D)增长小于阈值

14-17：根据高斯混合分布确定簇划分

## 密度聚类

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/cluster12.png)

### DBSCAN

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/cluster13.png)

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/cluster14.png)

核心对象：如果对象的Eps邻域至少包含最小数目MinPts的对象，则称该对象为核心对象。
边界点：边界点不是核心点，但落在某个核心点的邻域内。
噪音点：既不是核心点，也不是边界点的任何点

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/cluster15.png)

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/cluster16.png)

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/cluster17.png)

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/cluster18.png)