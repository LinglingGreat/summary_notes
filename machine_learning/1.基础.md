# 机器学习的流程与专业术语

### 什么是机器学习

**当经验以数据形式存储**，研究**算法**使得计算机可以从经验数据中学习，学习到的结果**(模型)**是可以对新情况**(更好地)** 完成**某个任务**。

训练经验E   性能标准P    任务T

###数据集

要进行机器学习，首先要有数据，这里我们又了一批关于西瓜的数据记录。这组记录的集合称为一个“数据集”(data set)

###示例/样本

数据集里每条记录对应关于一个对象（这里是西瓜）的描述，称为一个“示例”(instance)或“样本”(sample)

###属性/特征

每个样本对应的数据都反应了对象在某方面的表现或性质，例如“色泽”。这称为“属性”(attribute) 或“特征”(feature).

###属性值/特征值

每个样本对应的数据都反应了对象在某方面的表现或性质，例如“色泽”。这称为“属性”(attribute) 或“特征”(feature).某个特定样本对应的数据在某个属性上的值称为“属性值”或“特征值”。

###属性空间/特征空间

当我们用d个属性来表示一个对象。这d个属性相当于d个维度将张成一个d维的“属性空间”/“特征空间”。而每个样本对应的数据就是这个空间中的一个点，即一个n维向量，称为“特征向量”。

###标签/标记

机器学习的任务通常是对某些未知的信息（例如好瓜or坏瓜）做“预测”。用来标识样本关于未知信息的信息项成为“标签”。
“标签”的取值空间称为“标签空间”或“输出空间”。({0,1})

###训练/学习

从数据中学的模型的过程称为“学习”(learning)或“训练”(training), 这个过程通过执行某个算法来完成。

###训练数据

训练过程中使用的数据称为训练数据，其中每个样本称为训练样本。训练样本组成的集合称为训练集。

###测试

学得模型后，使用其进行预测的过程称为“测试”。被预测的样本称为“测试样本”

###分类/回归

当我们是用带有真实标签的训练集去学习到一个模型预测某些样本的标签。若我们欲预测标签的是离散值，此类学习任务称为“分类”，若欲预测的是连续值，此类学习任务称为“回归”。

###聚类

当我们的训练数据集中没有关于标签的信息。我们的任务是将训练集根据算法划分成若干个分组（“簇”）。这一任务将有助于我们了解数据内在的规律，以便更深入地分析数据。这样的学习任务称为“聚类”。

###监督学习/无监督学习

训练数据中有标记信息
-----监督学习(Supervised learning)
训练数据中没有标记信息
-----无监督学习(Unsupervised learning)

###强化学习

探索如何让机器在学习如何将场景（环境状态）映射到动作，以获取最大的奖赏。
例如探索如何让机器在种瓜过程中不断探索，最终总结出优秀种瓜策略

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/ml1.png)

### ==VC维==

参考 http://www.flickering.cn/machine_learning/2015/04/vc%E7%BB%B4%E7%9A%84%E6%9D%A5%E9%BE%99%E5%8E%BB%E8%84%89/

H的VC维表示为VC(H) ，指能够被H分散的最大集合的大小。若H能分散任意大小的集合，那么VC(H)为无穷大。 

{二维线性分类器}的VC维是3。 

更一般地,在r 维空间中,**线性决策面的VC维为r+1**。

### ==假设空间==

假设数据集有n种属性，第i个属性可能的取值有ti种，加上该属性的泛化取值(*)（比如什么颜色都是好瓜），所以可能的假设有$∏_i(ti+1)$。再用空集表示没有正例，假设空间中一共$∏_i(ti+1)+1$种假设。

### ==生成模型与判别式模型==

==判别式模型==：给定x，可通过直接建模P(c|x)来预测c。比如决策树，BP神经网络，支持向量机，条件随机场CRF，区分度训练，逻辑斯蒂回归，SVM，最近邻KNN，线性判别分析，Boosting，线性回归，CART，高斯过程

==生成式模型==：先对联合概率P(x,c)建模，然后得到P(c|x)。比如贝叶斯分类器，混合高斯模型，隐马尔科夫模型HMM，判别式分析，贝叶斯网络，Sigmoid Belief Networks，马尔科夫随机场，深度信念网络DBN

# 模型评估

## 什么是满意的模型/假设

### 泛化能力

机器学习的目标是使学得的模型能很好地适用于“新样本”，而不是仅仅在训练样本上工作得很好。即使对聚类这样的无监督学习任务，也希望学得的簇划分能适用于没在训练集中出现的样本。
模型适用于新样本的能力，成为“泛化”(generalization) 能力。

==具有强*泛化能力*的模型能很好地适用于**整个样本空间**==

==非监督学习算法对泛化能力也有要求==

####对训练集的偏好：

希望训练集能学习到适用于整个样本空间的假设。训练集作为样本空间的一个采样，能够很好地样本空间的全局特性。
假设样本空间中的样本服从一个未知分布
1.获得的训练样本都是独立地从这个分布上采样获得的，即“独立同分布”(independent and identically distributed, 简称i.i.d.)
2.样本数量尽可能多

####对假设和经验一致性的偏好：

对于新样本的预测标签与其真实标签尽可能一致（泛化误差低）

对于训练样本的预测标签与其真实标签尽可能一致（训练误差低）

为了对模型的泛化误差进行估计，通常将带标签的样本集抽取一部分出来作为“测试集”，其余作“训练集”，以在“测试集”上的“测试误差”作为“泛化误差”的近似。

####对假设复杂度的偏好：

“奥卡姆剃刀”（Occam’s razor）:
若有多个假设与观察一致，则选最简单的那个。
“简单有效原理”
“切勿浪费较多东西去做，用较少的东西，同样可以做好的事情。”

“没有免费的午餐”No free lunch theorem
All models are wrong, but some models are useful. —George Box
A set of assumptions that works well in one domain may work poorly in another

不要脱离了实际问题谈算法效果



## 效果度量

### 均方误差、错误率、精度

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/ml2.png)

### 查准率、查全率、PR图、F1分数

**推荐系统中常用到 **

“判断为不会违约的申请中有多少比例会违约”
“所有不会违约的申请中有多少比例被挑了出来”

根据其真实类别与学习器预测类别的组合划分：
真正例(true positive)、假正例(falsepositive)、真反例(true negative)、假反例(falsenegative)
令TP、FP、TN、FN分别表示对应的样例数(TP+FP+TN+FN=样例总数)
定义：分类结果的“混淆矩阵”(confusion matrix)

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/ml3.png)

| 真实情况 |  预测结果  |            |
| :------: | :--------: | :--------: |
|          |    正例    |    反例    |
|   正例   | TP(真正例) | FN(假反例) |
|   反例   | FP(假正例) | TN(真反例) |

按照某个学习器预测结果对样例进行排序
按照顺序逐个把样本作为正例进行预测
每次可以计算出当前的查全率、查准率
以查准率为纵轴、查全率为横轴做图，就得到了查准率-查全率曲线，简称“P-R曲线”

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/ml4.png)

### 真/假正例率、ROC曲线、AUC

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/ml5.png)

按照某个学习器预测结果对样例进行排序
按照顺序逐个把样本作为正例进行预测
每次计算出TPR与FPR，分别以它们为横、纵坐标作图

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/ml6.png)

### 代价敏感

在现实任务重常常会遇到情况：不同类型的错误所造成的后果不同
为权衡不同类型错误所造成的不同损失，我们为不同的错误赋予“非均等代价”(unequal cost)：
根据任务的领域知识设定一个“代价矩阵”(cost matrix)：

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/ml7.png)

##训练集和测试集的划分

###留出法

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/ml8.png)

不同训练/测试集的划分将导致不同的评估结果。
单次使用留出法得到的估计结果往往不够稳定可靠。
故一般要采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果。

==数据集包含1000个样本，其中500个正例、500个反例，将其划分为包含70%样本的训练集和30%样本的测试集用于留出法评估，试估算共有多少种划分方式。==

按对应比例分别从正例中和反例中采样即可。

$n=C_{500}^{350}*C_{500}^{350}$

![n = C{500}^{350} \times C{500}^{350} \approx 1.73 \times 10^{131}](https://www.zhihu.com/equation?tex=n+%3D+C%7B500%7D%5E%7B350%7D+%5Ctimes+C%7B500%7D%5E%7B350%7D+%5Capprox+1.73+%5Ctimes+10%5E%7B131%7D)

共有约 ![1.73 \times 10^{131}](https://www.zhihu.com/equation?tex=1.73+%5Ctimes+10%5E%7B131%7D) 种划分方法。

### 交叉验证法

![image](https://github.com/LinglingGreat/Quote/raw/master/img/ML/ml9.png)



# 处理缺失值

**数据清理中，处理缺失值的方法是?**

由于调查、编码和录入误差，数据中可能存在一些无效值和缺失值，需要给予适当的处理。常用的处理方法有：估算，整例删除，变量删除和成对删除。

估算(estimation)。最简单的办法就是用某个变量的样本均值、中位数或众数代替无效值和缺失值。这种办法简单，但没有充分考虑数据中已有的信息，误差可能较大。另一种办法就是根据调查对象对其他问题的答案，通过变量之间的相关分析或逻辑推论进行估计。例如，某一产品的拥有情况可能与家庭收入有关，可以根据调查对象的家庭收入推算拥有这一产品的可能性。

整例删除(casewise deletion)是剔除含有缺失值的样本。由于很多问卷都可能存在缺失值，这种做法的结果可能导致有效样本量大大减少，无法充分利用已经收集到的数据。因此，只适合关键变量缺失，或者含有无效值或缺失值的样本比重很小的情况。

变量删除(variable deletion)。如果某一变量的无效值和缺失值很多，而且该变量对于所研究的问题不是特别重要，则可以考虑将该变量删除。这种做法减少了供分析用的变量数目，但没有改变样本量。

成对删除(pairwise deletion)是用一个特殊码(通常是9、99、999等)代表无效值和缺失值，同时保留数据集中的全部变量和样本。但是，在具体计算时只采用有完整答案的样本，因而不同的分析因涉及的变量不同，其有效样本量也会有所不同。这是一种保守的处理方法，最大限度地保留了数据集中的可用信息。

采用不同的处理方法可能对分析结果产生影响，尤其是当缺失值的出现并非随机且变量之间明显相关时。因此，在调查中应当尽量避免出现无效值和缺失值，保证数据的完整性。

数据清理中，处理缺失值的方法有两种：
删除法：1）删除观察样本
​       2）删除变量：当某个变量缺失值较多且对研究目标影响不大时，可以将整个变量整体删除
​       3）使用完整原始数据分析：当数据存在较多缺失而其原始数据完整时，可以使用原始数据替代现有数据进行分析
​       4）改变权重：当删除缺失数据会改变数据结构时，通过对完整数据按照不同的权重进行加权，可以降低删除缺失数据带来的偏差
查补法：均值插补、回归插补、抽样填补等
成对删除与改变权重为一类
估算与查补法为一类