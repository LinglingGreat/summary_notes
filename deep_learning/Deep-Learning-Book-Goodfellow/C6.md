## 第六章 深度前馈网络

**深度前馈网络**（deep feedforward network），也叫作**前馈神经网络**（feedforward neural network）或者**多层感知机**（multilayer perceptron, MLP），是典型的深度学习模型。前馈网络的目标是近似某个函数$f^*$。例如，对于分类器，$y = f^*(x)$ 将输入x 映射到一个类别y。前馈网络定义了一个映射y = f(x; θ)，并且学习参数θ的值，使它能够得到最佳的函数近似。

前馈神经网络被称作**网络**（network）是因为它们通常用许多不同函数复合在一起来表示。该模型与一个有向无环图相关联，而图描述了函数是如何复合在一起的。例如，我们有三个函数$f^{(1)}, f^{(2)}, f^{(3)}$连接在一个链上以形成$f(x) = f^{(3)}(f^{(2)}(f^{(1)}(x)))$。这些链式结构是神经网络中最常用的结构。在这种情况下，$f^{(1)}$ 被称为网络的**第一层**（first layer），$f^{(2)}$  被称为**第二层**（second layer），以此类推。链的全长称为模型的**深度**（depth）。正是因为这个术语才出现了‘‘深度学习’’ 这个名字。前馈网络的最后一层被称为**输出层**（output layer）。

在神经网络训练的过程中，我们让$f(x)$去匹配$f^*(x)$的值，训练数据为我们提供了在不同训练点上取值的、含有噪声的$f^*(x)$的近似实例。每个样本x都伴随着一个标签$y\approx f^*(x)$。训练样本直接指明了输出层在每一点x上必须做什么：它必须产生一个接近y的值。但是没有直接指明其他层应该怎么做，学习算法必须决定如何使用这些层来产生想要的输出。因为训练数据并没有给出这些层中的每一层所需的输出，所以这些层被称为**隐藏层**（hidden layer）。

网络中的每个隐藏层通常都是向量值的。这些隐藏层的维数决定了模型的**宽度**（width）。

线性模型，例如逻辑回归和线性回归，是非常吸引人的，因为无论是通过闭解形式还是使用凸优化，它们都能高效且可靠地拟合。线性模型也有明显的缺陷，那就是该模型的能力被局限在线性函数里，所以它无法理解任何两个输入变量间的相互作用。

为了扩展线性模型来表示x 的非线性函数，我们可以不把线性模型用于x 本身，而是用在一个变换后的输入ϕ(x) 上，这里ϕ 是一个非线性变换。同样，我们可以使用第5.7.2 节中描述的核技巧，来得到一个基于隐含地使用ϕ 映射的非线性学习算法。我们可以认为ϕ 提供了一组描述x 的特征，或者认为它提供了x 的一个新的表示。

剩下的问题就是如何选择映射ϕ。

1. 其中一种选择是使用一个通用的ϕ，例如无限维的ϕ，它隐含地用在基于RBF 核的核机器上。如果ϕ(x) 具有足够高的维数，我们总是有足够的能力来拟合训练集，但是对于测试集的泛化往往不佳。非常通用的特征映射通常只基于局部光滑的原则，并且没有将足够的先验信息进行编码来解决高级问题。
2. 另一种选择是手动地设计ϕ。但是从业者各自擅长特定的领域（如语音识别或计算机视觉），并且不同领域之间很难迁移(transfer)。
3. 深度学习的策略是去学习ϕ。在这种方法中，我们有一个模型y = f(x; θ,w) =$ϕ(x; θ)^⊤w$。我们现在有两种参数：用于从一大类函数中学习ϕ 的参数θ，以及用于将ϕ(x) 映射到所需的输出的参数w。这是深度前馈网络的一个例子，其中ϕ 定义了一个隐藏层。这是三种方法中唯一一种放弃了训练问题的凸性的，但是利大于弊。在这种方法中，我们将表示参数化为ϕ(x; θ)，并且使用优化算法来寻找θ，使它能够得到一个好的表示。如果我们想要的话，这种方法也可以通过使它变得高度通用以获得第一种方法的优点——我们只需使用一个非常广泛的函数族ϕ(x; θ)。这种方法也可以获得第二种方法的优点。人类专家可以将他们的知识编码进网络来帮助泛化，他们只需要设计那些他们期望能够表现优异的函数族ϕ(x; θ) 即可。这种方法的优点是人类设计者只需要寻找正确的函数族即可，而不需要去寻找精确的函数。

### 6.1 实例：学习XOR

XOR 函数（‘‘异或’’ 逻辑）是两个二进制值x1 和x2 的运算。当这些二进制值中恰好有一个为1 时，XOR 函数返回值为1。其余情况下返回值为0。

在这个简单的例子中，我们不会关心统计泛化。我们希望网络在这四个点$X = \{[0, 0]^⊤, [0, 1]^⊤, [1, 0]^⊤, [1, 1]^⊤\}$ 上表现正确。我们会用全部这四个点来训练我们的网络，唯一的挑战是拟合训练集。

我们可以把这个问题当作是回归问题，并使用均方误差损失函数。我们选择这个损失函数是为了尽可能简化本例中用到的数学。

评估整个训练集上表现的MSE 损失函数为：

$J(\theta)=\frac 14 \sum_{x\in X}(f^*(x)-f(x;\theta))^2$

假设我们选择一个线性模型，定义成：

$f(x;w,b)=x^Tw+b$

我们可以使用正规方程关于w和b最小化$J(\theta)$，来得到一个闭式解：w=0, b=1/2。线性模型在任意一点都输出0.5。为什么会发生这种事？图6.1 演示了线性模型为什么不能用来表示XOR 函数。解决这个问题的其中一种方法是使用一个模型来学习一个不同的特征空间，在这个空间上线性模型能够表示这个解。

![1574083913355](img/6.1.png)

具体来说，我们这里引入一个非常简单的前馈神经网络，它有一层隐藏层并且隐藏层中包含两个单元。见图6.2 中对该模型的解释。

![1574084259484](img/6.2.png)

我们必须用非线性函数来描述这些特征。大多数神经网络通过仿射变换之后紧跟着一个被称为激活函数的固定非线性函数来实现这个目标。，默认的推荐是使用由激活函数g(z) = maxf{0, z}定义的**整流线性单元**（rectified linear unit）或者称为**ReLU** (Jarrett et al., 2009b; Nair and Hinton, 2010a; Glorot et al., 2011a)，如图6.3 所示。

![1574084447731](img/6.3.png)

我们的整个网络是

$f(x; W, c, w, b) = w^T\,max\{0, W^Tx+c\}+b$

我们可以给出XOR问题的一个解。令

$W=[[1, 1]^T, [1, 1]^T], c=[0, -1], w=[1, -2], b=0$

在结合之前给的X矩阵，代入计算，可以发现神经网络对每个样本都给出了正确的结果。

在这个例子中，我们简单地指定了解决方案，然后说明它得到的误差为零。在实际情况中，可能会有数十亿的模型参数以及数十亿的训练样本，所以不能像我们这里做的那样进行简单地猜解。与之相对的，基于梯度的优化算法可以找到一些参数使得产生的误差非常小。我们这里给出的XOR 问题的解处在损失函数的全局最小点，所以梯度下降算法可以收敛到这一点。梯度下降算法还可以找到XOR 问题一些其他的等价解。**梯度下降算法的收敛点取决于参数的初始值。**在实践中，梯度下降通常不会找到像我们这里给出的那种干净的、容易理解的、整数值的解。

### 6.2 基于梯度的学习

我们到目前为止看到的线性模型和神经网络的最大区别，在于**神经网络的非线性导致大多数我们感兴趣的代价函数都变得非凸**。这意味着神经网络的训练通常使用迭代的、基于梯度的优化，仅仅使得代价函数达到一个非常小的值；而不是像用于训练线性回归模型的线性方程求解器，或者用于训练逻辑回归或SVM 的凸优化算法那样保证全局收敛。凸优化从任何一种初始参数出发都会收敛（理论上如此——在实践中也很鲁棒但可能会遇到数值问题）。用于非凸损失函数的随机梯度下降没有这种收敛性保证，并且对参数的初始值很敏感。对于前馈神经网络，**将所有的权重值初始化为小随机数是很重要的。偏置可以初始化为零或者小的正值**。

我们当然也可以用梯度下降来训练诸如线性回归和支持向量机之类的模型，并且**事实上当训练集相当大时这是很常用的**。从这点来看，训练神经网络和训练其他任何模型并没有太大区别。计算梯度对于神经网络会略微复杂一些，但仍然可以很高效而精确地实现。

和其他的机器学习模型一样，为了使用基于梯度的学习方法我们必须选择一个代价函数，并且我们必须选择如何表示模型的输出。

#### 6.2.1 代价函数

神经网络的代价函数或多或少是和其他的参数模型例如线性模型的代价函数相同的。

##### 6.2.1.1 使用最大似然学习条件分布

大多数现代的神经网络使用最大似然来训练。这意味着代价函数就是负的对数似然，它与训练数据和模型分布间的交叉熵等价。这个代价函数表示为

$J(\theta)=-E_{x,y\sim \hat p_{data}}log\, p_{model}(y|x)$

代价函数的具体形式随着模型而改变，取决于$log\,p_{model}$ 的具体形式。

使用最大似然来导出代价函数的方法的一个优势是，它减轻了为每个模型设计代价函数的负担。明确一个模型p(y | x) 则自动地确定了一个代价函数log p(y | x)。

**贯穿神经网络设计的一个反复出现的主题是代价函数的梯度必须足够的大和具有足够的预测性，来为学习算法提供一个好的指引。**饱和（变得非常平）的函数破坏了这一目标，因为它们把梯度变得非常小。这在很多情况下都会发生，因为用于产生隐藏单元或者输出单元的输出的激活函数会饱和。负的对数似然帮助我们在很多模型中避免这个问题。很多输出单元都会包含一个指数函数，这在它的变量取绝对值非常大的负值时会造成饱和。负对数似然代价函数中的对数函数消除了某些输出单元中的指数效果。

用于实现最大似然估计的交叉熵代价函数有一个不同寻常的特性，那就是**当它被应用于实践中经常遇到的模型时，它通常没有最小值**。对于离散型输出变量，大多数模型以一种特殊的形式来参数化，即它们不能表示概率零和一，但是可以无限接近。逻辑回归是其中一个例子。对于实值的输出变量，如果模型可以控制输出分布的密度（例如，通过学习高斯输出分布的方差参数），那么它可能对正确的训练集输出赋予极其高的密度，这将导致交叉熵趋向负无穷。第七章中描述的正则化技术提供了一些不同的方法来修正学习问题，使得模型不会通过这种方式来获得无限制的收益。

##### 6.2.1.2 学习条件统计量

有时我们并不是想学习一个完整的概率分布p(y | x; θ)，而仅仅是想学习在给定x 时y 的某个条件统计量。

例如，我们可能有一个预测器f(x; )，我们想用它来预测y 的均值。如果我们使用一个足够强大的神经网络，我们可以认为这个神经网络能够表示一大类函数中的任何一个函数f，这个类仅仅被一些特征所限制，例如连续性和有界，而不是具有特殊的参数形式。从这个角度来看，我们可以把代价函数看作是一个泛函（functional）而不仅仅是一个函数。**泛函是函数到实数的映射。**我们因此可以将学习看作是选择一个函数而不仅仅是选择一组参数。我们可以设计代价泛函在我们想要的某些特殊函数处取得最小值。例如，我们可以设计一个代价泛函，使它的最小值处于一个特殊的函数上，这个函数将x 映射到给定x 时y 的期望值。对函数求解优化问题需要用到**变分法**（calculus of variations）这个数学工具，我们将在第19.4.2 节中讨论。

我们使用变分法导出的第一个结果是解优化问题

$f^*=\arg\min_f E_{x,y\sim p_{data}}||y-f(x)||^2$

得到

$f^*(x)=E_{y\sim p_{data}(y|x)}[y]$

要求这个函数处在我们要优化的类里。换句话说，如果我们能够用无穷多的、来源于真实的数据生成分布的样本进行训练，最小化均方误差代价函数将得到一个函数，它可以用来对每个x 的值预测出y 的均值。

不同的代价函数给出不同的统计量。第二个使用变分法得到的结果是

$f^*=\arg\min_f E_{x,y\sim p_{data}}||y-f(x)||_1$

将得到一个函数可以对每个x 预测y 取值的中位数，只要这个函数在我们要优化的函数族里。这个代价函数通常被称为**平均绝对误差**（mean absolute error）。

可惜的是，均方误差和平均绝对误差在使用基于梯度的优化方法时往往成效不佳。一些饱和的输出单元当结合这些代价函数时会产生非常小的梯度。这就是为什么交叉熵代价函数比均方误差或者平均绝对误差更受欢迎的原因之一了，即使是在没必要估计整个p(y | x) 分布时。

#### 6.2.2 输出单元



##### 6.2.2.1 用于高斯输出分布的线性单元



##### 6.2.2.2 用于Bernoulli输出分布的sigmoid单元



##### 6.2.2.3 用于Multinoulli输出分布的softmax单元



##### 6.2.2.4 其他的输出类型



### 6.3 隐藏单元