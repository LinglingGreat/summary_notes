## 第六章 深度前馈网络

**深度前馈网络**（deep feedforward network），也叫作**前馈神经网络**（feedforward neural network）或者**多层感知机**（multilayer perceptron, MLP），是典型的深度学习模型。前馈网络的目标是近似某个函数$f^*$。例如，对于分类器，$y = f^*(x)$ 将输入x 映射到一个类别y。前馈网络定义了一个映射y = f(x; θ)，并且学习参数θ的值，使它能够得到最佳的函数近似。

前馈神经网络被称作**网络**（network）是因为它们通常用许多不同函数复合在一起来表示。该模型与一个有向无环图相关联，而图描述了函数是如何复合在一起的。例如，我们有三个函数$f^{(1)}, f^{(2)}, f^{(3)}$连接在一个链上以形成$f(x) = f^{(3)}(f^{(2)}(f^{(1)}(x)))$。这些链式结构是神经网络中最常用的结构。在这种情况下，$f^{(1)}$ 被称为网络的**第一层**（first layer），$f^{(2)}$  被称为**第二层**（second layer），以此类推。链的全长称为模型的**深度**（depth）。正是因为这个术语才出现了‘‘深度学习’’ 这个名字。前馈网络的最后一层被称为**输出层**（output layer）。

在神经网络训练的过程中，我们让$f(x)$去匹配$f^*(x)$的值，训练数据为我们提供了在不同训练点上取值的、含有噪声的$f^*(x)$的近似实例。每个样本x都伴随着一个标签$y\approx f^*(x)$。训练样本直接指明了输出层在每一点x上必须做什么：它必须产生一个接近y的值。但是没有直接指明其他层应该怎么做，学习算法必须决定如何使用这些层来产生想要的输出。因为训练数据并没有给出这些层中的每一层所需的输出，所以这些层被称为**隐藏层**（hidden layer）。

网络中的每个隐藏层通常都是向量值的。这些隐藏层的维数决定了模型的**宽度**（width）。

线性模型，例如逻辑回归和线性回归，是非常吸引人的，因为无论是通过闭解形式还是使用凸优化，它们都能高效且可靠地拟合。线性模型也有明显的缺陷，那就是该模型的能力被局限在线性函数里，所以它无法理解任何两个输入变量间的相互作用。

为了扩展线性模型来表示x 的非线性函数，我们可以不把线性模型用于x 本身，而是用在一个变换后的输入ϕ(x) 上，这里ϕ 是一个非线性变换。同样，我们可以使用第5.7.2 节中描述的核技巧，来得到一个基于隐含地使用ϕ 映射的非线性学习算法。我们可以认为ϕ 提供了一组描述x 的特征，或者认为它提供了x 的一个新的表示。

剩下的问题就是如何选择映射ϕ。

1. 其中一种选择是使用一个通用的ϕ，例如无限维的ϕ，它隐含地用在基于RBF 核的核机器上。如果ϕ(x) 具有足够高的维数，我们总是有足够的能力来拟合训练集，但是对于测试集的泛化往往不佳。非常通用的特征映射通常只基于局部光滑的原则，并且没有将足够的先验信息进行编码来解决高级问题。
2. 另一种选择是手动地设计ϕ。但是从业者各自擅长特定的领域（如语音识别或计算机视觉），并且不同领域之间很难迁移(transfer)。
3. 深度学习的策略是去学习ϕ。在这种方法中，我们有一个模型y = f(x; θ,w) =$ϕ(x; θ)^⊤w$。我们现在有两种参数：用于从一大类函数中学习ϕ 的参数θ，以及用于将ϕ(x) 映射到所需的输出的参数w。这是深度前馈网络的一个例子，其中ϕ 定义了一个隐藏层。这是三种方法中唯一一种放弃了训练问题的凸性的，但是利大于弊。在这种方法中，我们将表示参数化为ϕ(x; θ)，并且使用优化算法来寻找θ，使它能够得到一个好的表示。如果我们想要的话，这种方法也可以通过使它变得高度通用以获得第一种方法的优点——我们只需使用一个非常广泛的函数族ϕ(x; θ)。这种方法也可以获得第二种方法的优点。人类专家可以将他们的知识编码进网络来帮助泛化，他们只需要设计那些他们期望能够表现优异的函数族ϕ(x; θ) 即可。这种方法的优点是人类设计者只需要寻找正确的函数族即可，而不需要去寻找精确的函数。

### 6.1 实例：学习XOR

XOR 函数（‘‘异或’’ 逻辑）是两个二进制值x1 和x2 的运算。当这些二进制值中恰好有一个为1 时，XOR 函数返回值为1。其余情况下返回值为0。

在这个简单的例子中，我们不会关心统计泛化。我们希望网络在这四个点$X = \{[0, 0]^⊤, [0, 1]^⊤, [1, 0]^⊤, [1, 1]^⊤\}$ 上表现正确。我们会用全部这四个点来训练我们的网络，唯一的挑战是拟合训练集。

我们可以把这个问题当作是回归问题，并使用均方误差损失函数。我们选择这个损失函数是为了尽可能简化本例中用到的数学。

评估整个训练集上表现的MSE 损失函数为：

$J(\theta)=\frac 14 \sum_{x\in X}(f^*(x)-f(x;\theta))^2$

假设我们选择一个线性模型，定义成：

$f(x;w,b)=x^Tw+b$

我们可以使用正规方程关于w和b最小化$J(\theta)$，来得到一个闭式解：w=0, b=1/2。线性模型在任意一点都输出0.5。为什么会发生这种事？图6.1 演示了线性模型为什么不能用来表示XOR 函数。解决这个问题的其中一种方法是使用一个模型来学习一个不同的特征空间，在这个空间上线性模型能够表示这个解。

![1574083913355](img/6.1.png)

具体来说，我们这里引入一个非常简单的前馈神经网络，它有一层隐藏层并且隐藏层中包含两个单元。见图6.2 中对该模型的解释。

![1574084259484](img/6.2.png)

我们必须用非线性函数来描述这些特征。大多数神经网络通过仿射变换之后紧跟着一个被称为激活函数的固定非线性函数来实现这个目标。，默认的推荐是使用由激活函数g(z) = maxf{0, z}定义的**整流线性单元**（rectified linear unit）或者称为**ReLU** (Jarrett et al., 2009b; Nair and Hinton, 2010a; Glorot et al., 2011a)，如图6.3 所示。

![1574084447731](img/6.3.png)

我们的整个网络是

$f(x; W, c, w, b) = w^T\,max\{0, W^Tx+c\}+b$

我们可以给出XOR问题的一个解。令

$W=[[1, 1]^T, [1, 1]^T], c=[0, -1], w=[1, -2], b=0$

在结合之前给的X矩阵，代入计算，可以发现神经网络对每个样本都给出了正确的结果。

在这个例子中，我们简单地指定了解决方案，然后说明它得到的误差为零。在实际情况中，可能会有数十亿的模型参数以及数十亿的训练样本，所以不能像我们这里做的那样进行简单地猜解。与之相对的，基于梯度的优化算法可以找到一些参数使得产生的误差非常小。我们这里给出的XOR 问题的解处在损失函数的全局最小点，所以梯度下降算法可以收敛到这一点。梯度下降算法还可以找到XOR 问题一些其他的等价解。**梯度下降算法的收敛点取决于参数的初始值。**在实践中，梯度下降通常不会找到像我们这里给出的那种干净的、容易理解的、整数值的解。

### 6.2 基于梯度的学习

我们到目前为止看到的线性模型和神经网络的最大区别，在于**神经网络的非线性导致大多数我们感兴趣的代价函数都变得非凸**。这意味着神经网络的训练通常使用迭代的、基于梯度的优化，仅仅使得代价函数达到一个非常小的值；而不是像用于训练线性回归模型的线性方程求解器，或者用于训练逻辑回归或SVM 的凸优化算法那样保证全局收敛。凸优化从任何一种初始参数出发都会收敛（理论上如此——在实践中也很鲁棒但可能会遇到数值问题）。用于非凸损失函数的随机梯度下降没有这种收敛性保证，并且对参数的初始值很敏感。对于前馈神经网络，**将所有的权重值初始化为小随机数是很重要的。偏置可以初始化为零或者小的正值**。

我们当然也可以用梯度下降来训练诸如线性回归和支持向量机之类的模型，并且**事实上当训练集相当大时这是很常用的**。从这点来看，训练神经网络和训练其他任何模型并没有太大区别。计算梯度对于神经网络会略微复杂一些，但仍然可以很高效而精确地实现。

和其他的机器学习模型一样，为了使用基于梯度的学习方法我们必须选择一个代价函数，并且我们必须选择如何表示模型的输出。

#### 6.2.1 代价函数

神经网络的代价函数或多或少是和其他的参数模型例如线性模型的代价函数相同的。

##### 6.2.1.1 使用最大似然学习条件分布

大多数现代的神经网络使用最大似然来训练。这意味着代价函数就是负的对数似然，它与训练数据和模型分布间的交叉熵等价。这个代价函数表示为

$J(\theta)=-E_{x,y\sim \hat p_{data}}log\, p_{model}(y|x)$

代价函数的具体形式随着模型而改变，取决于$log\,p_{model}$ 的具体形式。

使用最大似然来导出代价函数的方法的一个优势是，它减轻了为每个模型设计代价函数的负担。明确一个模型p(y | x) 则自动地确定了一个代价函数log p(y | x)。

**贯穿神经网络设计的一个反复出现的主题是代价函数的梯度必须足够的大和具有足够的预测性，来为学习算法提供一个好的指引。**饱和（变得非常平）的函数破坏了这一目标，因为它们把梯度变得非常小。这在很多情况下都会发生，因为用于产生隐藏单元或者输出单元的输出的激活函数会饱和。负的对数似然帮助我们在很多模型中避免这个问题。很多输出单元都会包含一个指数函数，这在它的变量取绝对值非常大的负值时会造成饱和。负对数似然代价函数中的对数函数消除了某些输出单元中的指数效果。

用于实现最大似然估计的交叉熵代价函数有一个不同寻常的特性，那就是**当它被应用于实践中经常遇到的模型时，它通常没有最小值**。对于离散型输出变量，大多数模型以一种特殊的形式来参数化，即它们不能表示概率零和一，但是可以无限接近。逻辑回归是其中一个例子。对于实值的输出变量，如果模型可以控制输出分布的密度（例如，通过学习高斯输出分布的方差参数），那么它可能对正确的训练集输出赋予极其高的密度，这将导致交叉熵趋向负无穷。第七章中描述的正则化技术提供了一些不同的方法来修正学习问题，使得模型不会通过这种方式来获得无限制的收益。

##### 6.2.1.2 学习条件统计量

有时我们并不是想学习一个完整的概率分布p(y | x; θ)，而仅仅是想学习在给定x 时y 的某个条件统计量。

例如，我们可能有一个预测器f(x; )，我们想用它来预测y 的均值。如果我们使用一个足够强大的神经网络，我们可以认为这个神经网络能够表示一大类函数中的任何一个函数f，这个类仅仅被一些特征所限制，例如连续性和有界，而不是具有特殊的参数形式。从这个角度来看，我们可以把代价函数看作是一个泛函（functional）而不仅仅是一个函数。**泛函是函数到实数的映射。**我们因此可以将学习看作是选择一个函数而不仅仅是选择一组参数。我们可以设计代价泛函在我们想要的某些特殊函数处取得最小值。例如，我们可以设计一个代价泛函，使它的最小值处于一个特殊的函数上，这个函数将x 映射到给定x 时y 的期望值。对函数求解优化问题需要用到**变分法**（calculus of variations）这个数学工具，我们将在第19.4.2 节中讨论。

我们使用变分法导出的第一个结果是解优化问题

$f^*=\arg\min_f E_{x,y\sim p_{data}}||y-f(x)||^2$

得到

$f^*(x)=E_{y\sim p_{data}(y|x)}[y]$

要求这个函数处在我们要优化的类里。换句话说，如果我们能够用无穷多的、来源于真实的数据生成分布的样本进行训练，最小化均方误差代价函数将得到一个函数，它可以用来对每个x 的值预测出y 的均值。

不同的代价函数给出不同的统计量。第二个使用变分法得到的结果是

$f^*=\arg\min_f E_{x,y\sim p_{data}}||y-f(x)||_1$

将得到一个函数可以对每个x 预测y 取值的中位数，只要这个函数在我们要优化的函数族里。这个代价函数通常被称为**平均绝对误差**（mean absolute error）。

可惜的是，均方误差和平均绝对误差在使用基于梯度的优化方法时往往成效不佳。一些饱和的输出单元当结合这些代价函数时会产生非常小的梯度。这就是为什么交叉熵代价函数比均方误差或者平均绝对误差更受欢迎的原因之一了，即使是在没必要估计整个p(y | x) 分布时。

#### 6.2.2 输出单元

任何可用作输出的神经网络单元，也可以被用作隐藏单元。

##### 6.2.2.1 用于高斯输出分布的线性单元

给定特征$h$，线性输出单元层产生一个向量$\hat y = W^Th+b$

线性输出层经常被用来产生条件高斯分布的均值：

$p(y|x)=N(y;\hat y, I)$

最大化其对数似然此时等价于最小化均方误差。

最大似然框架也使得学习高斯分布的协方差矩阵更加容易，或更容易地使高斯分布的协方差矩阵作为输入的函数。然而，对于所有输入，协方差矩阵都必须被限定成一个正定矩阵。线性输出层很难满足这种限定，所以通常使用其他的输出单元来对协方差参数化。

因为线性模型不会饱和，所以它们易于采用基于梯度的优化算法，甚至可以使用其他多种优化算法。

##### 6.2.2.2 用于Bernoulli输出分布的sigmoid单元

许多任务需要预测二值型变量y的值。

此时最大似然的方法是定义y在x条件下的Bernoulli分布。

Bernoulli分布仅需单个参数来定义。神经网络只需要预测P(y=1|x)即可，为了使这个数是有效的概率，它必须处在区间[0,1]中。

假设我们打算使用线性单元，并且通过阈值来限制它成为一个有效的概率：

$P(y=1|x)=max\{0, min\{1,w^Th+b\}\}$

这的确定义了一个有效的条件概率分布，但我们无法使用梯度下降来高效地训练它。当$w^Th+b$处于单位区间外时，模型的输出对其参数的梯度都将为0.梯度为0通常是有问题的，因为学习算法对于如何改善相应的参数不再具有指导意义。

相反，最好是使用一种新的方法来保证无论何时模型给出了错误的答案时，总能有一个较大的梯度。这种方法是基于使用sigmoid 输出单元结合最大似然来实现的。

sigmoid 输出单元定义为

$\hat y =\sigma(w^Th+b)$

其中$\sigma$是logistic sigmoid函数(第3.10节介绍的)。

我们可以认为sigmoid 输出单元具有两个部分。首先，它使用一个线性层来计算$z = w^⊤h + b$。接着，它使用sigmoid 激活函数将z 转化成概率。

那么是如何用z 的值来定义y 的概率分布的呢？总的来说，通过构造一个非归一化（和不为1）的概率分布$\tilde P(y)$ 可以得到sigmoid 。随后除以一个合适的常数就能得到有效的概率分布。

我们假定非归一化概率的对数对y和z是线性的，可以取指数来得到非归一化的概率。然后我们对它归一化，可以发现这服从Bernoulli分布，该分布受z的sigmoid变换控制：
$$
log\tilde P(y)=yz,\\
\tilde P(y)=exp(yz),\\
P(y)=\frac{exp(yz)}{\sum_{y'=0}^1 exp(y'z)},\\
P(y)=\sigma((2y-1)z)
$$
基于指数和归一化的概率分布在统计建模的文献中很常见。用于定义这种二值型变量分布的变量z 被称为**分对数**（logit）。

这种在对数空间里预测概率的方法可以很自然地使用最大似然学习。因为用于最大似然的代价函数是-log P(y | x)，代价函数中的log 抵消了sigmoid 中的exp。如果没有这个效果，sigmoid 的饱和性会阻止基于梯度的学习做出好的改进。我们使用最大似然来学习一个由sigmoid 参数化的Bernoulli 分布，它的损失函数为
$$
J(\theta)=-logP(y|x)=-log\sigma((2y-1)z)=\zeta((1-2y)z)
$$
通过将损失函数写成softplus 函数的形式，我们可以看到它仅仅在(1 - 2y)z 取绝对值非常大的负值时才会饱和。因此饱和只会出现在模型已经得到正确答案时——当y = 1 且z 取非常大的正值时，或者y = 0 且z 取非常小的负值时。当z 的符号错误时，softplus 函数的变量(1 - 2y)z可以简化为|z|。当|z| 变得很大并且z 的符号错误时，softplus 函数渐近地趋向于它的变量|z|。对z 求导则渐近地趋向于sign(z)，所以，对于极限情况下极度不正确的z，softplus 函数完全不会收缩梯度。这个性质很有用，因为它意味着基于梯度的学习可以很快地改正错误的z。

当我们使用其他的损失函数，例如均方误差之类的，损失函数会在σ(z) 饱和时饱和。sigmoid 激活函数在z 取非常小的负值时会饱和到0，当z 取非常大的正值时会饱和到1。这种情况一旦发生，梯度会变得非常小以至于不能用来学习，无论此时模型给出的是正确还是错误的答案。因此，**最大似然几乎总是训练sigmoid 输出单元的优选方法**。

理论上，sigmoid 的对数总是确定和有限的，因为sigmoid 的返回值总是被限制在开区间(0, 1) 上，而不是使用整个闭区间[0, 1] 的有效概率。在软件实现时，为了避免数值问题，最好将负的对数似然写作z 的函数，而不是$\hat y = \sigma(z) $的函数。如果sigmoid 函数下溢到零，那么之后对$\hat y$ 取对数会得到负无穷。

##### 6.2.2.3 用于Multinoulli输出分布的softmax单元

任何时候当我们想要表示一个具有n 个可能取值的离散型随机变量的分布时，我们都可以使用softmax 函数。它可以看作是sigmoid 函数的扩展，其中sigmoid 函数用来表示二值型变量的分布。

softmax 函数最常用作分类器的输出，来表示n 个不同类上的概率分布。比较少见的是，softmax 函数可以在模型内部使用，例如如果我们想要在某个内部变量的n 个不同选项中进行选择。

在二值型变量的情况下，我们希望计算一个单独的数$\hat y=P(y=1|x)$，因为这个数需要处在0 和1 之间，并且我们想要让这个数的对数可以很好地用于对数似然的基于梯度的优化，我们选择去预测另外一个数$z = log \hat P(y = 1 | x)$。对其指数化和归一化，我们就得到了一个由sigmoid 函数控制的Bernoulli 分布。

为了推广到具有n 个值的离散型变量的情况，我们现在需要创造一个向量$\hat y$，它的每个元素是$\hat y_i = P(y = i | x)$。我们不仅要求每个$\hat y_i$ 元素介于0 和1 之间，还要使得整个向量的和为1，使得它表示一个有效的概率分布。用于Bernoulli 分布的方法同样可以推广到Multinoulli 分布。首先，线性层预测了未归一化的对数概率：

$z=W^Th+b$

其中$z_i=log\hat P(y=i|x)$。softmax函数然后可以对z指数化和归一化来获得需要的$\hat y$。最终，softmax函数的形式为

$softmax(z)_i=\frac{exp(z_i)}{\sum_j exp(z_j)}$

和logistic sigmoid一样，当使用最大化对数似然训练softmax 来输出目标值y时，使用指数函数工作地非常好。这种情况下，我们想要最大化$log P(y = i; z) =log\,softmax(z)_i$。将softmax 定义成指数的形式是很自然的因为对数似然中的log 可以抵消softmax 中的exp：

$log\,softmax(z)_i=z_i-log\sum_j exp(z_j)$

第一项表示输入$z_i$ 总是对代价函数有直接的贡献。因为这一项不会饱和，所以即使$z_i$ 对第二项的贡献很小，学习依然可以进行。当最大化对数似然时，第一项鼓励$z_i$ 被推高，而第二项则鼓励所有的z 被压低。为了对第二项有一个直观的理解，注意到这一项可以大致近似为$max_j z_j$。这种近似是基于对任何明显小于$max_j z_j$的$z_k$，$exp(z_k)$ 都是不重要的。我们能从这种近似中得到的直觉是，负对数似然代价函数总是强烈地惩罚最活跃的不正确预测。如果正确答案已经具有了softmax 的最大输入，那么$- z_j$项和$logΣ_j exp(z_j) \approx max_j z_j = z_i$项将大致抵消。这个样本对于整体训练代价贡献很小，这个代价主要由其他未被正确分类的样本产生。



##### 6.2.2.4 其他的输出类型



### 6.3 隐藏单元